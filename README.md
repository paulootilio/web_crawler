Sobre
========
web_crawler Ã© uma aplicaÃ§Ã£o de rastreamento e raspagem da web de alto nÃ­vel, usada para rastrear sites e extrair dados estruturados de suas pÃ¡ginas.

<!-- Requisitos -->
## :books: Requisitos
- Ter [**Git**](https://git-scm.com/) para clonar o projeto.
- Ter [**Docker**](https://www.docker.com/) para rodar o projeto.

<!-- ComeÃ§ando -->
## :gear: ComeÃ§ando

instruÃ§Ãµes sobre como configurar o projeto localmente.
```bash
# Entrar no diretÃ³rio da aplicaÃ§Ã£o:
  $ cd web_crawler

  # Subir containers:
  $ docker-compose up -d

  # Criar o banco e rodar as migrations:
  $ docker-compose run myapp bundle exec rake db:create db:migrate

  # Rodar a aplicaÃ§Ã£o:
  $ docker-compose up
```

Feito por Paulo Otilio ğŸ‘‹ğŸ» [Get in touch!](https://github.com/paulootilio)